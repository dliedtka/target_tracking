{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using ParticleFilters\n",
    "using Distributions\n",
    "using StaticArrays\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using StatsBase\n",
    "using Reel\n",
    "using POMDPs\n",
    "#using POMDPSimulators\n",
    "#using POMDPPolicies\n",
    "#using POMDPModelTools\n",
    "using GridInterpolations\n",
    "using DataStructures\n",
    "using DataFrames\n",
    "using CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"atan2.jl\")\n",
    "include(\"obs.jl\")\n",
    "include(\"polargrid.jl\")\n",
    "rng = MersenneTwister(2); # A very good random number generator, internal to Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the POMDP struct.\n",
    "# I am unclear as to how this struct is useful in this analysis.\n",
    "\n",
    "# Implement the POMDP, here.\n",
    "\n",
    "mutable struct targetPOMDP <: POMDP{Vector{Float64}, Tuple{Float64}, Int64}\n",
    "    p_walk::Float64\n",
    "    discount::Float64\n",
    "end\n",
    "\n",
    "# statespace = [(10*r,θ*15, crs*15, hdg*15, spd) for r in 0:30, θ in 1:12, crs in 1:12, hdg in 1:12, spd in 1:2]\n",
    "\n",
    "###\n",
    "\n",
    "targetPOMDP() = targetPOMDP(0.9, 0.9)\n",
    "POMDPs.actions(::targetPOMDP) = ((30,1),(0,1),(-30,1),(30, 2), (0,2), (-30,2))\n",
    "POMDPs.actionindex(::targetPOMDP, a::Tuple) = (a[1]/30+1)*2 + a[2] #cleverness returns 1-6\n",
    "POMDPs.states(::targetPOMDP) = statespace\n",
    "POMDPs.stateindex(::targetPOMDP, s::NTuple{5,Int64}) = LinearIndices(statespace)[s[1]/10, s[2]/30, s[3]/30, s[4]/30, s[5]]\n",
    "\n",
    "###\n",
    "\n",
    "# POMDPs.stateindex(::targetPOMDP, s::NTuple{5,Int64}) = LinearIndices(statespace)[round(Int,s[1]/10)+1, round(Int,s[2]/30)+1,\n",
    "#    (round(Int,s[3]/30)+1, round(Int,s[4]/30)+1, round(Int,s[5])+1]\n",
    "\n",
    "###\n",
    "\n",
    "POMDPs.observations(::targetPOMDP) = (0, 1, 2, 3)\n",
    "POMDPs.obsindex(::targetPOMDP, o::Int64) = o + 1\n",
    "\n",
    "POMDPs.initialstate_distribution(::targetPOMDP) = ParticleCollection([[5, 60, 90, 90, 1] for i in 1:N])\n",
    "POMDPs.initialstate(::targetPOMDP, rng::AbstractRNG) = [5, 60, 90, 90, 1]\n",
    "POMDPs.isterminal(::targetPOMDP,s) = s[1] >= 300\n",
    "POMDPs.discount(::targetPOMDP) = 0.9\n",
    "\n",
    "###\n",
    "\n",
    "# General creation of a POMDP.\n",
    "\n",
    "function POMDPs.gen(m::targetPOMDP, s, a, rng)\n",
    "    return (sp=f(s,a,rng), r=r(s), o=h(s,rng))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "targetPOMDP(0.9, 0.9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation of a POMDP using the initialized struct.\n",
    "\n",
    "pomdp = targetPOMDP(0.9, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "next_crs (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing the next course of action.\n",
    "\n",
    "#input is course in degrees and rng\n",
    "#returns next course in degrees\n",
    "\n",
    "function next_crs(crs,rng)\n",
    "    if rand(rng) < pomdp.p_walk\n",
    "        return crs\n",
    "    end\n",
    "    crs = (crs + rand(rng,[-1,1])*30) % 360\n",
    "    if crs < 0 crs += 360 end\n",
    "    return crs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing the function used for the random walk...\n",
    "# which tries to understand the the observations created when walking in random directions.\n",
    "\n",
    "# state as tuple (x, y, crs, hdg) of target (hdg of o/s)\n",
    "\n",
    "function f(state, control, rng)\n",
    "    r, θ, crs, hdg, spd = state\n",
    "    x = r*cos(π/180*θ)\n",
    "    y = r*sin(π/180*θ)\n",
    "    pos = [x + TGT_SPD*cos(π/180*crs) - spd*cos(π/180*hdg), y + TGT_SPD*sin(π/180*crs) - spd*sin(π/180*hdg)]\n",
    "    crs = next_crs(crs,rng)\n",
    "    hdg = hdg + control[1]\n",
    "    hdg = hdg % 360\n",
    "    \n",
    "    if hdg < 0\n",
    "        hdg += 360\n",
    "    end\n",
    "    \n",
    "    spd = control[2]\n",
    "    r = sqrt(pos[1]^2 + pos[2]^2)\n",
    "    θ = atan2(pos[1],pos[2])*180/π\n",
    "    \n",
    "    #if trunc(Int, atan2(pos[1],pos[2])*180/π) == 0\n",
    "    #    @show pos\n",
    "    #end\n",
    "    \n",
    "    if θ < 0 θ += 360 end\n",
    "    \n",
    "    return (r, θ, crs, hdg, spd)::NTuple{5, Real}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing the reward function.\n",
    "\n",
    "function r(s::NTuple{5,Real})\n",
    "    range = s[1]\n",
    "    if range > 150 return -1 end  # reward to not lose track of contact\n",
    "    if range <= 10 return -1000 end  # collision avoidance\n",
    "    return 2  # being in \"sweet spot\" maximizes reward\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the random walk.\n",
    "\n",
    "POS_0 = [6.0, 60.0]\n",
    "CRS_0 = 90 # target's course (TARGET)\n",
    "HDG_0 = 90 # o/s heading (UAV)\n",
    "SPD_0 = 1 # 1 or 2\n",
    "TGT_SPD = 1\n",
    "\n",
    "x = []\n",
    "courses = []\n",
    "observs = []\n",
    "\n",
    "rew = 0\n",
    "\n",
    "for i in 1:10000\n",
    "    state = f((POS_0[1], POS_0[2], CRS_0, HDG_0, SPD_0),(0,1),rng)\n",
    "    POS_0[1], POS_0[2], CRS_0, HDG_0, SPD_0 = state\n",
    "    θ = state[2]\n",
    "    rad = state[1]\n",
    "    if θ < 0 θ += 360 end\n",
    "    push!(courses, CRS_0)\n",
    "    push!(observs,(rad, θ, obs0(state), obs1(state), obs2(state), obs3(state)))\n",
    "    # println(observs[i])\n",
    "    \n",
    "    rew += r(state)\n",
    "    \n",
    "end\n",
    "\n",
    "# plot(observs[:,2], observs[:,1], proj=:polar, m=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "observs_filter = zeros(10000,6)\n",
    "\n",
    "for iter1 in (1:10000)\n",
    "    \n",
    "    for iter2 in (1:6)\n",
    "        \n",
    "        observs_filter[iter1, iter2] = observs[iter1][iter2]\n",
    "        \n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how to plot this, when you have time for this.\n",
    "\n",
    "#=\n",
    "\n",
    "plot(observs_filter[:,2], observs_filter[:,1], proj=:polar, m=2)\n",
    "\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########\n",
    "\n",
    "# I need to do something with this.\n",
    "\n",
    "angles = [0, 30, 60, 90, 120, 150, 210, 240, 270, 300, 330]\n",
    "\n",
    "statespace = thestates\n",
    "actionspace = ((30,1), (0,1), (-30,1), (30, 2), (0,2), (-30,2))\n",
    "\n",
    "action_index(a) = trunc(Int, 2*(a[1]/30+1) + a[2])\n",
    "actions_ = ((-30,1), (-30, 2), (0, 1), (0, 2), (30, 1), (30, 2))\n",
    "\n",
    "observations = (0, 1, 2, 3)\n",
    "\n",
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f2 (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SIR Particle Filter - I don't know what this is used for.\n",
    "\n",
    "N = 500\n",
    "updater = SIRParticleFilter(pomdp, N);\n",
    "\n",
    "### This changes the original \"random walk\".\n",
    "### In this case, this will be used for the implementation of the reinforcement learning algorithm.\n",
    "\n",
    "function f2(x, u, rng)\n",
    "    temp = [i for i in f(x, u, rng)]\n",
    "    return temp\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This initializes (some grid interpolation ... ???) the rewards for all combinations of states.\n",
    "\n",
    "#θ = zeros(length(grid),6);\n",
    "θ = [r(Tuple(ind2x(grid, j))) for j in 1:length(grid), i in 1:6];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "model = ParticleFilterModel{Vector{Float64}}(f2, g)\n",
    "pfilter = SIRParticleFilter(model, N);\n",
    "α = 0.5\n",
    "γ = 0.95\n",
    "ϵ = 0.3\n",
    "x = [20, 60, 90, 90, 1];\n",
    "λ = 0.8\n",
    "b = ParticleCollection([[20, 60, 90, 90, 1] for i in 1:N]);\n",
    "counter = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "\n",
    "## Q-learning loop\n",
    "plots = [];\n",
    "betas = Deque{Array}();\n",
    "β = zeros(length(grid),6);\n",
    "\n",
    "epochs = 1000;\n",
    "last = 0;\n",
    "\n",
    "total = 0;\n",
    "ξ = weighted_grid_2(b)/N;\n",
    "\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "\n",
    "counter = 0;\n",
    "i = 1;\n",
    "counter += 1;\n",
    "u = next_action([transpose(θ[:,j])*ξ for j in 1:size(θ)[2]], ϵ, rng);\n",
    "\n",
    "#observe new state and reward\n",
    "xp = f2(x, actions_[u], rng);\n",
    "o = h(xp, rng); \n",
    "b = update(pfilter, b, actions_[u], o); # filter, belief states, action, observation\n",
    "\n",
    "rew = r(Tuple(xp));\n",
    "ξ = weighted_grid_2(b)/N;\n",
    "β[:,u] = ξ;\n",
    "\n",
    "total += rew\n",
    "#v = 10^3*sqrt(var(ξ))\n",
    "if length(betas) < 20\n",
    "    pushfirst!(betas, β)\n",
    "else\n",
    "    pop!(betas)\n",
    "    pushfirst!(betas, β)\n",
    "end\n",
    "\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast-informed bound (FIB) loop\n",
    "\n",
    "### Need to do, later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ((-30,1), (-30, 2), (0, 1), (0, 2), (30, 1), (30, 2));\n",
    "observations = (0, 1, 2, 3);\n",
    "# θ = [r(Tuple(ind2x(grid, j))) for j in 1:length(grid), i in 1:6];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual States for each state parameter.\n",
    "\n",
    "states_r = [10.0*r for r in 1:30]\n",
    "states_θ = [30.0*θ for θ in 0:12]\n",
    "# states_crs = [30*c for c in 1:12]\n",
    "states_hdg = [30*h for h in 1:12]\n",
    "states_spd = [1,2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RectangleGrid{4}([10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0  …  210.0, 220.0, 230.0, 240.0, 250.0, 260.0, 270.0, 280.0, 290.0, 300.0],[0.0, 30.0, 60.0, 90.0, 120.0, 150.0, 180.0, 210.0, 240.0, 270.0, 300.0, 330.0, 360.0],[30.0, 60.0, 90.0, 120.0, 150.0, 180.0, 210.0, 240.0, 270.0, 300.0, 330.0, 360.0],[1.0, 2.0],)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a matrix for all possible state combinations.\n",
    "\n",
    "length_states = length(states_r) * length(states_θ) * length(states_hdg) * length(states_spd) # length(states_crs) * \n",
    "# states = zeros(length_states, 5);\n",
    "states = RectangleGrid(states_r, states_θ, states_hdg, states_spd) # , states_crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through all possible state combinations and inserting them into the \"states\" matrix.\n",
    "\n",
    "#=\n",
    "\n",
    "count_row = 0\n",
    "\n",
    "for r in states_r\n",
    "    \n",
    "    for θ in states_θ\n",
    "        \n",
    "        for crs in states_crs\n",
    "            \n",
    "            for hdg in states_hdg\n",
    "                \n",
    "                for spd in states_spd\n",
    "                    \n",
    "                    count_row += 1\n",
    "                    \n",
    "                    states[count_row, 1] = r\n",
    "                    states[count_row, 2] = θ\n",
    "                    states[count_row, 3] = crs\n",
    "                    states[count_row, 4] = hdg\n",
    "                    states[count_row, 5] = spd\n",
    "                    \n",
    "                end\n",
    "                \n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particle Filter Parameters\n",
    "\n",
    "N = 500;\n",
    "model = ParticleFilterModel{Vector{Float64}}(f2, g)\n",
    "pfilter = SIRParticleFilter(model, N);\n",
    "b_particle = ParticleCollection([[20, 60, 90, 90, 1] for i in 1:N]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateBelief (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update Belief\n",
    "\n",
    "function UpdateBelief(beta, act, obs)\n",
    "   \n",
    "    beta_new = zeros(length(beta), 1);\n",
    "    \n",
    "    P = 0;\n",
    "    sts_count = 0;\n",
    "    \n",
    "    for sts in states\n",
    "        \n",
    "        sts_prime_count = 0;\n",
    "        obs_trans_sum = 0;\n",
    "        \n",
    "        for sts_prime in states\n",
    "           \n",
    "            sts_prime_count += 1;\n",
    "            obs_trans_sum += g(nothing, act, sts_prime, obs) * 0.9;\n",
    "            \n",
    "        end\n",
    "        \n",
    "        sts_count += 1;\n",
    "        P += beta[sts_count] * obs_trans_sum;\n",
    "        \n",
    "    end\n",
    "    \n",
    "    sts_beta_new_count = 0;\n",
    "    \n",
    "    for sts_beta_new in states\n",
    "       \n",
    "        trans_belief_sum = 0;\n",
    "        sts_belief_count = 0;\n",
    "        \n",
    "        for sts_belief in states\n",
    "            \n",
    "            sts_belief_count += 1;\n",
    "            trans_belief_sum += 0.9 * beta[sts_belief_count];\n",
    "            \n",
    "        end\n",
    "        \n",
    "        sts_beta_new_count += 1;\n",
    "        beta_new[sts_beta_new_count] = ( g(nothing, act, sts_beta_new, obs) / P ) * trans_belief_sum\n",
    "        \n",
    "    end\n",
    "    \n",
    "    println(length(beta_new))\n",
    "    \n",
    "    return beta_new\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BackupBelief (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Backup Belief Update\n",
    "\n",
    "function BackupBelief(lambda, beta)\n",
    "    \n",
    "    alpha_all = zeros(size(lambda)[1], 6)\n",
    "    \n",
    "    count_a = 0\n",
    "    \n",
    "    for act in actions\n",
    "        \n",
    "        count_a += 1\n",
    "        \n",
    "        alpha_o = zeros(size(lambda)[1], 4)\n",
    "        \n",
    "        count_o = 0\n",
    "        \n",
    "        for obs in observations\n",
    "            \n",
    "            betaP = beta # UpdateBelief(beta, act, obs)\n",
    "            \n",
    "            count_o += 1\n",
    "            arg_max_alpha_o = maximum(LinearIndices(CartesianIndices(findmax( transpose(lambda) * betaP )[2])))\n",
    "            alpha_o[:,count_o] += lambda[:,arg_max_alpha_o]\n",
    "            \n",
    "        end\n",
    "        \n",
    "        count_s = 0\n",
    "        \n",
    "        for sts in states\n",
    "            \n",
    "            count_o = 0\n",
    "            \n",
    "            count_s += 1\n",
    "            \n",
    "            obs_alpha_act_obs = 0\n",
    "            \n",
    "            for obs_sum in observations\n",
    "                \n",
    "                count_o += 1\n",
    "            \n",
    "                obs_alpha_act_obs += g(nothing, act, sts, obs_sum) * 0.9 * alpha_o[count_s, count_o]\n",
    "                \n",
    "            end\n",
    "            \n",
    "            alpha_all[count_s, count_a] = r(tuple(sts)) + γ * obs_alpha_act_obs\n",
    "            \n",
    "        end\n",
    "        \n",
    "    end\n",
    "        \n",
    "    arg_max_alpha_all = maximum(LinearIndices(CartesianIndices(findmax( transpose(alpha_all) * beta )[2])))\n",
    "    alpha_return = alpha_all[:,arg_max_alpha_all]\n",
    "    \n",
    "    println(\"---\")\n",
    "    println(size(alpha_return))\n",
    "    println(\"---\")\n",
    "    \n",
    "    return alpha_return\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "\n",
    "a = [1 3 54 6 89 0 3]\n",
    "maximum(LinearIndices(CartesianIndices(findmax(a)[2])))\n",
    "\n",
    "=#\n",
    "\n",
    "# reward(tuple(states[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedPointBasedUpdate (generic function with 1 method)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomized Point Based Update\n",
    "\n",
    "function RandomizedPointBasedUpdate(BETA, Lambda)\n",
    "    \n",
    "    LambdaP = [] # Array{Float64,1}\n",
    "    BETA_P = BETA\n",
    "    \n",
    "    while (BETA_P != [])\n",
    "        \n",
    "        rand_num = rand(1:length(BETA_P))\n",
    "        beta = BETA_P[rand_num]\n",
    "        \n",
    "        alpha = BackupBelief(beta, Lambda)\n",
    "        \n",
    "        cond_left = transpose(alpha) * beta\n",
    "        cond_right = findmax( transpose(Lambda) * beta )[1]\n",
    "        \n",
    "        # println(cond_left >= cond_right)\n",
    "        \n",
    "        if (cond_left >= cond_right)\n",
    "            \n",
    "            push!(LambdaP, alpha)\n",
    "            \n",
    "        else\n",
    "            \n",
    "            arg_max_alpha = maximum(LinearIndices(CartesianIndices(findmax( transpose(Lambda) * beta )[2])))\n",
    "            println(arg_max_alpha)\n",
    "            alphaP = Lambda[arg_max_alpha]\n",
    "            push!(LambdaP, alphaP)\n",
    "            \n",
    "        end\n",
    "        \n",
    "        BETA_P_new = []\n",
    "        \n",
    "        count_beta = 0\n",
    "        \n",
    "        for beta_P in BETA_P\n",
    "            \n",
    "            count_beta += 1\n",
    "            println(count_beta)\n",
    "            \n",
    "            # println(size(LambdaP[1]))\n",
    "            \n",
    "            # println(size(LambdaP))\n",
    "            \n",
    "            cond_left_new = findmax( transpose(LambdaP[1]) * beta_P )[1]\n",
    "            cond_right_new = findmax( transpose(Lambda) * beta_P )[1]\n",
    "            \n",
    "            # println(findmax( transpose(LambdaP) * beta_P ))\n",
    "            # println(findmax( transpose(Lambda) * beta_P ))\n",
    "            \n",
    "            println(cond_left_new < cond_right_new)\n",
    "            \n",
    "            if ( cond_left_new < cond_right_new )\n",
    "            \n",
    "                push!(BETA_P_new, beta_P)\n",
    "                    \n",
    "            end\n",
    "            \n",
    "        end\n",
    "        \n",
    "        BETA_P = BETA_P_new\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return LambdaP\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the value to initialize alpha with.\n",
    "\n",
    "state_min_rew = [1, 0, 0, 0, 0];\n",
    "min_rew = r(Tuple(state_min_rew));\n",
    "alpha_init = 1 / (1 - γ) * min_rew;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the alpha array.\n",
    "\n",
    "alpha_start = zeros(length_states, 6);\n",
    "alpha_start .+= alpha_init;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the beta belief state.\n",
    "\n",
    "beta_start = zeros(length_states, 6);\n",
    "beta_start .+= (1/length_states);\n",
    "\n",
    "beta_start_tuple = []\n",
    "\n",
    "for counter in 1:6\n",
    "    \n",
    "    push!(beta_start_tuple, beta_start[:,counter])\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta_start_tuple;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "(9360,)\n",
      "---\n",
      "1\n",
      "false\n",
      "2\n",
      "false\n",
      "3\n",
      "false\n",
      "4\n",
      "false\n",
      "5\n",
      "false\n",
      "6\n",
      "false\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Any,1}:\n",
       " [-999.9999086538462, 2.0000913461538463, 2.0000913461538463, 2.0000913461538463, 2.0000913461538463, 2.0000913461538463, 2.0000913461538463, 2.0000913461538463, 2.0000913461538463, 2.0000913461538463  …  -0.9999086538461538, -0.9999086538461538, -0.9999086538461538, -0.9999086538461538, -0.9999086538461538, -0.9999086538461538, -0.9999086538461538, -0.9999086538461538, -0.9999086538461538, -0.9999086538461538]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rand = RandomizedPointBasedUpdate(beta_start_tuple, alpha_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r (generic function with 2 methods)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implementing the reward function.\n",
    "\n",
    "function r(s::Tuple{Array{Float64,1}})\n",
    "    range = s[1][1]\n",
    "    if range > 150 return -1 end  # reward to not lose track of contact\n",
    "    if range <= 10 return -1000 end  # collision avoidance\n",
    "    return 2  # being in \"sweet spot\" maximizes reward\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initializing the alpha vestors for all possible states\n",
    "\n",
    "alphaQMDP = zeros(length_states, 6);\n",
    "# findmax(alphaQMDP[1,:])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fully Observable Value Approximation - QMDP\n",
    "\n",
    "function QMDP(alpha_start)\n",
    "    \n",
    "    for k in 1\n",
    "    \n",
    "        state_count = 0\n",
    "    \n",
    "        for sts in states\n",
    "        \n",
    "            state_count += 1\n",
    "            action_count = 0\n",
    "            println(state_count)\n",
    "        \n",
    "            for act in actions\n",
    "            \n",
    "                action_count += 1;\n",
    "                transition_action_sum = 0;\n",
    "                state_prime_count = 0\n",
    "            \n",
    "                for sts_prime in states\n",
    "                \n",
    "                    state_prime_count += 1;\n",
    "                    transition_action_sum += γ * 0.9 * findmax(alpha_start[state_prime_count,action_count])[1]\n",
    "                \n",
    "                end\n",
    "            \n",
    "                alpha_start[state_count, action_count] = r(tuple(sts)) + transition_action_sum\n",
    "            \n",
    "            end       \n",
    "        \n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return alpha_start\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fully Observable Value Approximation - FIB\n",
    "\n",
    "function FIB(alpha_start)\n",
    "    \n",
    "    for k in 1\n",
    "    \n",
    "        state_count = 0;\n",
    "    \n",
    "        for sts in states\n",
    "        \n",
    "            state_count += 1;\n",
    "            action_count = 0;\n",
    "            println(state_count)\n",
    "        \n",
    "            for act in actions\n",
    "            \n",
    "                action_count += 1;\n",
    "                obs_count = 0;\n",
    "                sum_obs = 0;\n",
    "            \n",
    "                for obs in observations\n",
    "                \n",
    "                    act_prime_count = 0;\n",
    "                    sum_state_action = zeros(1, 6);\n",
    "                    \n",
    "                    for act_prime in actions\n",
    "                        \n",
    "                        act_prime_count += 1;\n",
    "                        sts_prime_count = 0;\n",
    "                        \n",
    "                        for sts_prime in states\n",
    "                            \n",
    "                            sts_prime_count += 1\n",
    "                            sum_state_action[1,act_prime_count] += g(nothing, act_prime, sts_prime, obs) * 0.9 * alpha_start[sts_prime_count, act_prime_count];\n",
    "                            \n",
    "                        end\n",
    "                        \n",
    "                    end\n",
    "                    \n",
    "                    sum_obs += findmax(sum_state_action)[1];\n",
    "                    \n",
    "                end\n",
    "                \n",
    "                alpha_start[state_count, action_count] += r(tuple(sts)) + γ * sum_obs;\n",
    "                \n",
    "            end       \n",
    "        \n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return alpha_start\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup Belief for the Point-Based Value Iteration\n",
    "\n",
    "### NEED TO FINISH!!!\n",
    "\n",
    "function BackupBelief(Lambda, beta)\n",
    "    \n",
    "    for act in actions\n",
    "        \n",
    "        for obs in observations\n",
    "            \n",
    "            b_prime = UpdateBelief(beta, act, obs)\n",
    "            \n",
    "            alpha[act_count, obs_count] = findmax( transpose(Lambda) * beta_prime )\n",
    "            \n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    for sts in states\n",
    "        \n",
    "        alpha = \n",
    "        \n",
    "    end\n",
    "    \n",
    "    alpha = findmax( transpose(alpha) * beta )\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_QMDP = QMDP(alphaQMDP);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_FIB = FIB(alphaQMDP);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for counter in 1:9360\n",
    "    \n",
    "    println(test_FIB[counter,1] - test_FIB[counter,2])\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Q-learning loop\n",
    "plots = []\n",
    "betas = Deque{Array}()\n",
    "β = zeros(length(grid),6);\n",
    "\n",
    "epochs = 1000\n",
    "last = 0\n",
    "\n",
    "total = 0\n",
    "ξ = weighted_grid_2(b)/N\n",
    "for i in 1:(1500*epochs)\n",
    "    counter += 1\n",
    "    \n",
    "    # choose next action\n",
    "    u = next_action([transpose(θ[:,j])*ξ for j in 1:size(θ)[2]], ϵ, rng)\n",
    "    \n",
    "    #observe new state and reward\n",
    "    xp = f2(x, actions_[u], rng)\n",
    "    obs = h(xp, rng)\n",
    "    b = update(pfilter, b, actions_[u], obs)\n",
    "    rew = r(Tuple(xp))\n",
    "    \n",
    "    ξ = weighted_grid_2(b)/N # This is the interpolation.\n",
    "    \n",
    "    β[:,u] = ξ\n",
    "    \n",
    "    total += rew\n",
    "    #v = 10^3*sqrt(var(ξ))\n",
    "    if length(betas) < 20\n",
    "        pushfirst!(betas, β)\n",
    "    else\n",
    "        pop!(betas)\n",
    "        pushfirst!(betas, β)\n",
    "    end\n",
    "        \n",
    "    cur = (rew + γ * max2([transpose(θ[:,j])*ξ for j in 1:size(θ)[2]], rng) - last)\n",
    "    #println(cur)\n",
    "\n",
    "    #update θ\n",
    "    #θ += α * cur *β\n",
    "    for (j, bet) in enumerate(betas)\n",
    "        θ += (λ^j) * α * cur * bet\n",
    "    end\n",
    "    \n",
    "    last = transpose(θ[:,u])*ξ\n",
    "    \n",
    "    x = xp\n",
    "    \n",
    "    #=\n",
    "    \n",
    "    if counter % 1500 == 0\n",
    "        push!(totals, total/2)\n",
    "        #ϵ = max(min((20000 - 2*total)/180000, 1), 0)\n",
    "        println(\"--------- CURRENT: \", total/2, \" AVG: \", mean(totals), \" Epoch: \", \n",
    "            trunc(Int, counter/500), \" -----------\")\n",
    "        total = 0\n",
    "        xp = [rand(rng, 25:120), rand(rng,0:360), rand(rng,0:11)*30, 1, 1];\n",
    "        b = ParticleCollection([xp[1:4] for i in 1:N]);\n",
    "        last = 0\n",
    "        sleep(3)\n",
    "    end\n",
    "    \n",
    "    =#\n",
    "    \n",
    "    #plotting\n",
    "    #r_ = [row[1] for row in particles(b)]\n",
    "    #theta = [row[2] for row in particles(b)]*π/180\n",
    "    #x_theta = x[2]*π/180\n",
    "    #x_r = x[1]\n",
    "    \n",
    "    #print(\".\")\n",
    "    #plt = plot(proj=:polar, lims=(0,200), size=(1000,1000))\n",
    "    #scatter!(theta, r_, markersize=1, label=\"particles\")\n",
    "    #scatter!([x_theta], [x_r], markersize=3, label=\"target\")\n",
    "          \n",
    "    #push!(plots, plt)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = POMDPEnvironment(targetPOMDP())\n",
    "\n",
    "function simulate(env::AbstractEnvironment, nsteps::Int = 100)\n",
    "    done = false\n",
    "    r_tot = 0.0\n",
    "    step = 1\n",
    "    o = reset!(env)\n",
    "    while !done && step <= nsteps\n",
    "        action = sample_action(env) # take random action \n",
    "        obs, rew, done, info = step!(env, action)\n",
    "        obs = trunc(Int,obs[1])\n",
    "        #@show obs, rew, done, info\n",
    "        r_tot += rew\n",
    "        step += 1\n",
    "    end\n",
    "    return r_tot\n",
    "end\n",
    "\n",
    "@show simulate(env)\n",
    "#ac = sample_action(env)\n",
    "#step!(env, ac)\n",
    "\n",
    "# Link: https://github.com/JuliaPOMDP/RLInterface.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
